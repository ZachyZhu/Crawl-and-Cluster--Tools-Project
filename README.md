#A description of what has been implemented
#Installation instructions (if any besides cloning the repo)
#Python packages should be listed appropriately in requirements.txt
#Run instructions
#What do I need to type to get your program to do its thing

# Crawl-and-Cluster--Tools Project
Our group name: Fantastic Four. Group members: Zeqi Zhu(zz2568), Qi Li(ql2336), Jiani Lu(jl5240), Xiao Liang(xl2817)
Enrolled in IEOR E4501 Section 001

Description: Our project was carried out in following steps.

First part, we wrote a web crawler that searches the house prices on www.streeteasy.com in Manhanttan Area, New York. The codes for this part are listed as "crawl.py" and "crawl.ipynb". There are some differences between these two code. For the "crawl.py", you have to change the cookie......, because the website has anti-crawl setting. For the "crawl.ipynb", we wrote a "for loop" to figure out the anti-crawl problem, you can crawl all the data by exctuing the code only once.

Second step, we carried out analysis on the data we collected, based on the â€œK-means Clustering Algorithm". The codes for this part are listed as "CSV merge and process.ipynb" and "K-means.ipynb". The "CSV merge and process.ipynb" is used to clean the raw data we initially collected from the website, the raw data are listed in the "datafile.csv", the data after being clearned are saved in the "processed_data.csv". Then the "K-means.ipynb" is used to 

